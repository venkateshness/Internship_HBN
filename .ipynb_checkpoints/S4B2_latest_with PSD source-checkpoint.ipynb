{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pathlib\n",
    "from mne.externals.pymatreader import read_mat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import axes3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing & Parsing the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=112, n_times=176386\n",
      "    Range : 0 ... 176385 =      0.000 ...   352.770 secs\n",
      "Ready.\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_to_file = 'data/Good subjects/NDARBF805EHN/EEG/preprocessed/csv_format/RestingState_data.csv'\n",
    "path_to_events = 'data/Good subjects/NDARBF805EHN/EEG/preprocessed/csv_format/RestingState_event.csv'\n",
    "path_to_montage_glob = 'GSN_HydroCel_129_hbn.sfp'\n",
    "path_to_montage_ses = 'data/Good subjects/NDARBF805EHN/EEG/preprocessed/csv_format/RestingState_chanlocs.csv'\n",
    "fs = 500\n",
    "chans_glob = mne.channels.read_custom_montage(fname = 'GSN_HydroCel_129_hbn.sfp') # read_montage is deprecated\n",
    "# channels to exclude because noisy (Nentwich paper)\n",
    "ch_list=['E1', 'E8', 'E14', 'E17', 'E21', 'E25', 'E32', 'E38', 'E43', 'E44', 'E48', 'E49', 'E56', 'E57', 'E63', 'E64', 'E69', 'E73', 'E74', 'E81', 'E82', 'E88', 'E89', 'E94', 'E95', 'E99', 'E100', 'E107', 'E113', 'E114', 'E119', 'E120', 'E121', 'E125', 'E126', 'E127', 'E128']\n",
    "\n",
    "\n",
    "def csv_to_raw_mne(path_to_file,path_to_montage_ses,fs,path_to_events,montage = 'GSN-HydroCel-129'):\n",
    "    ''' Load csv files of data, chan locations and events and return a raw mne instance'''\n",
    "    data = np.loadtxt(path_to_file,delimiter =',')\n",
    "    chans = pd.read_csv(path_to_montage_ses,sep = ',',header = None)\n",
    "    \n",
    "    ch_names = list(chans.values[1:,0])\n",
    "#print(type(ch_names))\n",
    "    ch_names_appended = list(np.append(ch_names,'stim_channel'))\n",
    "\n",
    "    types = ['eeg']*(len(ch_names_appended)-1)\n",
    "    types.append('stim')\n",
    "    data2 = np.zeros([1,176386]) #len(raw.times)\n",
    "    data_appended = np.append(data,data2,axis = 0)\n",
    "\n",
    "    #print(np.shape(data_appended))\n",
    "#print(len(types))\n",
    "\n",
    "#types\n",
    "    info = mne.create_info(ch_names_appended,sfreq = fs,ch_types = types)\n",
    "#raw=mne.io.RawArray(data, info)\n",
    "\n",
    "#mne.find_events(raw,stim_channel='stim')\n",
    "    raw = mne.io.RawArray(data_appended, info)\n",
    "    \n",
    "    # set standard montage\n",
    "    if montage:\n",
    "        raw.set_montage(montage)\n",
    "        raw.set_eeg_reference(projection=True) \n",
    "\n",
    "    # events array shape must be (n_events,3)The first column specifies the sample number of each event,\n",
    "    # the second column is ignored, and the third column provides the event value.\n",
    "    # If events already exist in the Raw instance at the given sample numbers, the event values will be added together.\n",
    "\n",
    "    if path_to_events:\n",
    "        # parse events file\n",
    "        raw_events = pd.read_csv(path_to_events, sep = r'\\s*,\\s*', header = None, engine = 'python')\n",
    "        values = raw_events[0].to_list()\n",
    "    \n",
    "        # identify markers start and stop recording\n",
    "        idx = [i for i, e in enumerate(values) if e == 'break cnt']\n",
    "\n",
    "        samples = raw_events[1][idx[0] + 1:idx[1]].to_numpy(dtype = int)\n",
    "        # slicing until '-1' means that we will not know about the last state. Hence removed.\n",
    "        event_values = raw_events[0][idx[0] + 1:idx[1]].to_numpy(dtype = int)\n",
    "\n",
    "        \n",
    "        # append a last value for end of paradigm\n",
    "        ## I think 1 acts as an explicit EOF, but having this slicing until '-1' as indicated\n",
    "        # in the previous comment would not let us know the last state\n",
    "        # event_values = np.append(event_values, 1)\n",
    "\n",
    "        # Creating an array of len(samples)-1 would not have the sufficient length to add the \n",
    "        # sample's last row.\n",
    "        events = np.zeros((len(samples), 3))\n",
    "        \n",
    "        events = events.astype('int')\n",
    "        events[:, 0] = samples\n",
    "        events[:, 2] = event_values\n",
    "        \n",
    "        # Appending one row of 'ones'. Will be easier to stop parsing once we hit 1\n",
    "        events_final = np.append(events,np.ones((1, 3)),axis = 0).astype('int')\n",
    "        raw = exclude_channels_from_raw(raw, ch_list)\n",
    "        \n",
    "    return raw,events_final\n",
    "\n",
    "def exclude_channels_from_raw(raw,ch_to_exclude):\n",
    "    '''Return a raw structure where ch_to_exclude are removed'''\n",
    "    idx_keep = mne.pick_channels(raw.ch_names,include = raw.ch_names,exclude = ch_to_exclude)\n",
    "    raw.pick_channels([raw.ch_names[pick] for pick in idx_keep])\n",
    "    return raw\n",
    "\n",
    "\n",
    "raw, events = csv_to_raw_mne(path_to_file,path_to_montage_ses,fs,path_to_events,montage = 'GSN-HydroCel-129')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding events into the raw structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw.add_events(events[:-1], stim_channel = 'stim_channel',replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([0.00000e+00, 2.00000e-03, 4.00000e-03, ..., 3.52766e+02,\n",
       "        3.52768e+02, 3.52770e+02]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['stim_channel']#sanity check, it produces 2 arrays.. the last one is just the time slots. 3.52e+02 = 352seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>114 points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 91 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Info | 9 non-empty values\n",
       " bads: []\n",
       " ch_names: E2, E3, E4, E5, E6, E7, E9, E10, E11, E12, E13, E15, E16, E18, ...\n",
       " chs: 91 EEG, 1 STIM\n",
       " custom_ref_applied: False\n",
       " dig: 114 items (3 Cardinal, 111 EEG)\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 250.0 Hz\n",
       " meas_date: unspecified\n",
       " nchan: 92\n",
       " projs: Average EEG reference: off\n",
       " sfreq: 500.0 Hz\n",
       ">"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# kind = kinda standard which has 3D coordinates for 128 electrodes and 3 default things\n",
    "montage_plot = mne.channels.make_standard_montage(kind= \"GSN-HydroCel-129\")  \n",
    "# Note: By default, the 3d plots displayed here does not show the 3rd axis, thus require a\n",
    "# a package called qt, can be called with %matplotlib qt\n",
    "##%matplotlib notebook\n",
    "##fig = montage_plot.plot(kind='3d')\n",
    "##fig.gca().view_init(azim=70, elev=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data in time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Layout({\n",
       "    'annotations': [{'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E2',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E3',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y2'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E4',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y3'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E5',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y4'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E6',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y5'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E7',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y6'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E9',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y7'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E10',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y8'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E11',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y9'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E12',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y10'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E13',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y11'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E15',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y12'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E16',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y13'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E18',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y14'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E19',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y15'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E20',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y16'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E22',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y17'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E23',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y18'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E24',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y19'},\n",
       "                    {'font': {'size': 9},\n",
       "                     'showarrow': False,\n",
       "                     'text': 'E26',\n",
       "                     'x': -0.06,\n",
       "                     'xref': 'paper',\n",
       "                     'y': 0,\n",
       "                     'yref': 'y20'}],\n",
       "    'autosize': False,\n",
       "    'height': 600,\n",
       "    'showlegend': False,\n",
       "    'width': 1000,\n",
       "    'yaxis': {'domain': [0.95, 1], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis10': {'domain': [0.5, 0.55], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis11': {'domain': [0.44999999999999996, 0.5], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis12': {'domain': [0.3999999999999999, 0.44999999999999996],\n",
       "                'showgrid': False,\n",
       "                'showticklabels': False,\n",
       "                'zeroline': False},\n",
       "    'yaxis13': {'domain': [0.35, 0.3999999999999999], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis14': {'domain': [0.29999999999999993, 0.35], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis15': {'domain': [0.25, 0.29999999999999993], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis16': {'domain': [0.19999999999999996, 0.25], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis17': {'domain': [0.1499999999999999, 0.19999999999999996],\n",
       "                'showgrid': False,\n",
       "                'showticklabels': False,\n",
       "                'zeroline': False},\n",
       "    'yaxis18': {'domain': [0.09999999999999998, 0.1499999999999999],\n",
       "                'showgrid': False,\n",
       "                'showticklabels': False,\n",
       "                'zeroline': False},\n",
       "    'yaxis19': {'domain': [0.04999999999999993, 0.09999999999999998],\n",
       "                'showgrid': False,\n",
       "                'showticklabels': False,\n",
       "                'zeroline': False},\n",
       "    'yaxis2': {'domain': [0.9, 0.95], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis20': {'domain': [0.0, 0.04999999999999993], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis3': {'domain': [0.85, 0.9], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis4': {'domain': [0.8, 0.85], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis5': {'domain': [0.75, 0.8], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis6': {'domain': [0.7, 0.75], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis7': {'domain': [0.6499999999999999, 0.7], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis8': {'domain': [0.6, 0.6499999999999999], 'showgrid': False, 'showticklabels': False, 'zeroline': False},\n",
       "    'yaxis9': {'domain': [0.55, 0.6], 'showgrid': False, 'showticklabels': False, 'zeroline': False}\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plotly.graph_objs import Layout, YAxis, Scatter, Annotation, Annotations, Data, Figure, Marker, Font\n",
    "from plotly import tools\n",
    "from plotly import graph_objects\n",
    "import chart_studio.plotly as py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_channels = 20\n",
    "start, stop = raw.time_as_index([0, 5])\n",
    "picks = mne.pick_channels(raw.ch_names, include=raw.ch_names[:n_channels], exclude=[])\n",
    "\n",
    "\n",
    "data, times = raw[picks[:n_channels], start:stop]\n",
    "ch_names = [raw.info['ch_names'][p] for p in picks[:n_channels]]\n",
    "#ch_names\n",
    "\n",
    "\n",
    "step = 1. / n_channels\n",
    "kwargs = dict(domain=[1 - step, 1], showticklabels=False, zeroline=False, showgrid=False)\n",
    "\n",
    "# create objects for layout and traces\n",
    "layout = Layout(yaxis=YAxis(kwargs), showlegend=False)\n",
    "traces = [Scatter(x=times, y=data.T[:, 0])]\n",
    "\n",
    "# loop over the channels\n",
    "for ii in range(1, n_channels):\n",
    "        kwargs.update(domain=[1 - (ii + 1) * step, 1 - ii * step])\n",
    "        layout.update({'yaxis%d' % (ii + 1): YAxis(kwargs), 'showlegend': False})\n",
    "        traces.append(Scatter(x=times, y=data.T[:, ii], yaxis='y%d' % (ii + 1)))\n",
    "\n",
    "# add channel names using Annotations\n",
    "annotations = Annotations([Annotation(x=-0.06, y=0, xref='paper', yref='y%d' % (ii + 1),\n",
    "                                      text=ch_name, font=Font(size=9), showarrow=False)\n",
    "                          for ii, ch_name in enumerate(ch_names)])\n",
    "layout.update(annotations=annotations)\n",
    "\n",
    "# set the size of the figure and plot it\n",
    "layout.update(autosize=False, width=1000, height=600)\n",
    "#fig = Figure(data=Data(traces), layout=layout)\n",
    "#fig.show()\n",
    "#fig.write_html(\"raw_time_domain.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch (ing) the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "12 matching events found\n",
      "Setting baseline interval to [0.0, 20.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Loading data for 12 events and 10001 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11, 92, 5000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = mne.Epochs(raw, events[:-1], [20,30,90], tmin=0, tmax=20,preload=True,baseline=(0,None))\n",
    "epochs_resampled = epochs.resample(250)\n",
    "np.shape(epochs_resampled.load_data())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.58409631e+00 -8.18878558e-01  2.81844831e+00 ...  4.52789963e-03\n",
      "   2.07484308e+00  3.93024530e+00]\n",
      " [ 6.53901394e+00  1.27377559e+00 -2.94062442e+00 ... -8.92677892e+00\n",
      "  -9.67254170e+00 -1.06168450e+01]\n",
      " [-6.93891178e+00 -1.98165323e+00  3.12380739e+00 ...  5.18470655e+00\n",
      "   8.01368388e+00  9.22337828e+00]\n",
      " ...\n",
      " [ 4.10320804e+00  6.48407734e-01 -1.91441106e+00 ... -6.71186813e+00\n",
      "  -6.69504774e+00 -7.49493978e+00]\n",
      " [ 3.65310369e+00  9.82614309e-01 -1.61844898e+00 ... -5.19645865e+00\n",
      "  -5.63366523e+00 -5.53457346e+00]\n",
      " [ 2.24960874e+01 -6.14398001e+00  3.39749992e+00 ... -2.91433743e-03\n",
      "   2.91632953e-03 -2.91832477e-03]]\n"
     ]
    }
   ],
   "source": [
    "for i in epochs_resampled[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topo Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layout = mne.find_layout(epochs.info)\n",
    "##epochs.average().plot_topo(layout=layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##mne.viz.plot_events(events[:-1], sfreq=raw.info['sfreq'])\n",
    "#The last event 20 falls on 174120 and the last sample is 176386. That's just 4 seconds before the end of the EEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw PSD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##mne.viz.plot_raw_psd(raw,tmax=40,fmax=40,picks=['E22','E20','E23'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 3e-07 (2.2e-16 eps * 11 dim * 1.2e+08  max singular value)\n",
      "    Estimated rank (eeg): 11\n",
      "    EEG: rank 11 computed from 91 data channels with 1 projector\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 91 -> 11\n",
      "Estimating covariance using SHRUNK\n",
      "Done.\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Using cross-validation to select the best estimator.\n",
      "Number of samples used : 11\n",
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -217.287\n",
      "   empirical: -246.661\n",
      "selecting best estimator: shrunk\n",
      "[done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-0a62af761410>:2: RuntimeWarning:\n",
      "\n",
      "Too few samples (required : 460 got : 11), covariance estimate may be unreliable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plotting covariance\n",
    "covariance = mne.compute_covariance(\n",
    "    epochs_resampled, tmax=0., method=['shrunk', 'empirical'], rank=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topomap PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#epochs\n",
    "##mne.viz.plot_epochs_psd_topomap(epochs['20']) # Eyes open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSD plot for the electrodes located in Occipital lobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "##for i in range(0,5): #0 is 90 = beginning of EEG, so skipped\n",
    "    #plt.title('event ={}. Note: open = 20'.format(events[i][2])) this works nicely if plotted through qt\n",
    "  ##  print(\"\\t\\t\\tEVENT IN THE GRAPH BELOW IS = {}\".format(events[i][2]))\n",
    "    ##print(\"\\t\\t\\tNOTE, EYES OPEN = 20 & EYES CLOSE = 30\")\n",
    "    ##print(\"\\t\\t\\tOnset at {}s\".format(events[i][0]/500))\n",
    "    ##mne.viz.plot_raw_psd(raw,tmin= events[i][0]/500,tmax=events[i+1][0]/500,fmax=40,picks=['E70','E75','E83'])\n",
    "\n",
    "    \n",
    "# Types of waves: https://www.sciencedirect.com/topics/agricultural-and-biological-sciences/brain-waves\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#for i in range(1,5): #0 is 90 = beginning of EEG, so skipped\n",
    "    #plt.title('event ={}. Note: open = 20'.format(events[i][2])) this works nicely if plotted through qt\n",
    "    #print(\"\\t\\t\\tEVENT IN THE GRAPH BELOW IS = {}\".format(events[i][2]))\n",
    "    #print(\"\\t\\t\\tNOTE, EYES OPEN = 20 & EYES CLOSE = 30\")\n",
    "    #mne.viz.plot_raw_psd(raw,tmin= events[i][0]/500,tmax=events[i+1][0]/500,fmax=40,picks=['E34','E33'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up BEM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files missing from root.txt in /homes/v20subra/mne_data/MNE-fsaverage-data\n",
      "0 files missing from bem.txt in /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage\n"
     ]
    }
   ],
   "source": [
    "from mne.datasets import fetch_fsaverage\n",
    "\n",
    "import os.path as op\n",
    "fs_dir = fetch_fsaverage(verbose=True)\n",
    "subjects_dir = op.dirname(fs_dir)\n",
    "\n",
    "\n",
    "subject = 'fsaverage' # Subject ID for the MRI-head transformation\n",
    "trans = 'fsaverage'  # MNE has a built-in fsaverage transformation\n",
    "source_space = op.join(fs_dir, 'bem', 'fsaverage-ico-5-src.fif') \n",
    "bem = op.join(fs_dir, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif') # BEM model is called faverage I guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source space          : /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif\n",
      "MRI -> head transform : /homes/v20subra/.local/lib/python3.8/site-packages/mne/data/fsaverage/fsaverage-trans.fif\n",
      "Measurement data      : instance of Info\n",
      "Conductor model   : /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n",
      "Accurate field computations\n",
      "Do computations in head coordinates\n",
      "Free source orientations\n",
      "\n",
      "Reading /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif...\n",
      "Read 2 source spaces a total of 20484 active source locations\n",
      "\n",
      "Coordinate transformation: MRI (surface RAS) -> head\n",
      "     0.999994  0.003552  0.000202      -1.76 mm\n",
      "    -0.003558  0.998389  0.056626      31.09 mm\n",
      "    -0.000001 -0.056626  0.998395      39.60 mm\n",
      "     0.000000  0.000000  0.000000       1.00\n",
      "\n",
      "Read  91 EEG channels from info\n",
      "Head coordinate coil definitions created.\n",
      "Source spaces are now in head coordinates.\n",
      "\n",
      "Setting up the BEM model using /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif...\n",
      "\n",
      "Loading surfaces...\n",
      "\n",
      "Loading the solution matrix...\n",
      "\n",
      "Three-layer model surfaces loaded.\n",
      "Loaded linear_collocation BEM solution from /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n",
      "Employing the head->MRI coordinate transform with the BEM model.\n",
      "BEM model fsaverage-5120-5120-5120-bem-sol.fif is now set up\n",
      "\n",
      "Source spaces are in head coordinates.\n",
      "Checking that the sources are inside the surface and at least    5.0 mm away (will take a few...)\n",
      "    Skipping interior check for 2433 sources that fit inside a sphere of radius   47.7 mm\n",
      "    Skipping solid angle check for 0 points using Qhull\n",
      "    Skipping interior check for 2241 sources that fit inside a sphere of radius   47.7 mm\n",
      "    Skipping solid angle check for 0 points using Qhull\n",
      "\n",
      "Setting up for EEG...\n",
      "Computing EEG at 20484 source locations (free orientations)...\n",
      "\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "fwd_model = mne.make_forward_solution(raw.info, trans=trans, src=source_space, bem=bem, eeg=True, mindist=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse operator with the known forward operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n",
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 0.29 (2.2e-16 eps * 91 dim * 1.4e+13  max singular value)\n",
      "    Estimated rank (eeg): 11\n",
      "    EEG: rank 11 computed from 91 data channels with 1 projector\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 2.41121\n",
      "    scaling factor to adjust the trace = 6.7756e+07 (nchan = 91 nzero = 80)\n"
     ]
    }
   ],
   "source": [
    "from mne.minimum_norm import make_inverse_operator, apply_inverse, apply_inverse_epochs\n",
    "\n",
    "inverse_operator = make_inverse_operator(raw.info, fwd_model, covariance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Created the whitener using a noise covariance matrix with rank 11 (80 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Processing epoch : 1 / 5\n",
      "combining the current components...\n",
      "Processing epoch : 2 / 5\n",
      "combining the current components...\n",
      "Processing epoch : 3 / 5\n",
      "combining the current components...\n",
      "Processing epoch : 4 / 5\n",
      "combining the current components...\n",
      "Processing epoch : 5 / 5\n",
      "combining the current components...\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "method = \"eLORETA\"\n",
    "snr = 3.\n",
    "lambda2 = 1. / snr ** 2\n",
    "\n",
    "# epochs['30'].average() = Averaged evoked response for the event 30\n",
    "stc = apply_inverse_epochs(epochs_resampled['20'], inverse_operator, lambda2,\n",
    "                              method=method, pick_ori=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid GUI request 'qt # Solves the black-screen on mayavi front. This 5 letters, 2 words took me hours and hours to figure out :D', valid ones are:dict_keys(['inline', 'nbagg', 'notebook', 'ipympl', 'widget', None, 'qt4', 'qt', 'qt5', 'wx', 'tk', 'gtk', 'gtk3', 'osx', 'asyncio'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [7.90981298e-06 8.65465463e-06 1.43173850e-05]\n"
     ]
    }
   ],
   "source": [
    "vertno_max, time_max = stc[0].get_peak()\n",
    "%matplotlib qt\n",
    "%gui qt # Solves the black-screen on mayavi front. This 5 letters, 2 words took me hours and hours to figure out :D\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(1e3 * stc[0].times, stc[0].data[::100, :].T)\n",
    "ax.set(xlabel='time (ms)', ylabel='%s value' % method)\n",
    "brain = stc[0].plot(subjects_dir=subjects_dir, initial_time=time_max, time_unit='s',hemi='both')\n",
    "#surfer_kwargs = dict(\n",
    " #   hemi='both', subjects_dir=subjects_dir,\n",
    "  #  clim=dict(kind='value', lims=[8, 12, 15]), views='lateral',\n",
    "   # initial_time=time_max, time_unit='s', size=(800, 800), smoothing_steps=10)\n",
    "#brain = stc.plot(**surfer_kwargs)\n",
    "brain.add_foci(vertno_max, coords_as_verts=True, hemi='rh', color='blue',scale_factor=0.6, alpha=0.5)\n",
    "brain.add_foci(vertno_max, coords_as_verts=True, hemi='lh', color='red',scale_factor=0.6, alpha=0.5)\n",
    "\n",
    "brain.add_text(0.1, 0.9, 'eLORETA', 'title' ,font_size=14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gearing up for computing PSD at source level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mne.minimum_norm import read_inverse_operator, compute_source_psd_epochs\n",
    "from mne.datasets import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Created the whitener using a noise covariance matrix with rank 11 (80 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 11\n",
      "Using 78 tapers with bandwidth 4.0 Hz on 1 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411c8539468d469db43ea5ff1360f7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using control points [3.74949704e-11 1.16665778e-10 1.17594123e-09]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.0, 0.0, 430.9261779785156, array([0., 0., 0.])), 0.0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stc2=stc[0].in_label(mne.Label(inverse_operator['src'][0]['vertno'], hemi='lh') +\n",
    "    #              mne.Label(inverse_operator['src'][1]['vertno'], hemi='rh'))\n",
    "    \n",
    "\n",
    "data_path = sample.data_path()\n",
    "label_name ='Vis-rh.label' # Have to use 2 labels at the same, but will deal with this later\n",
    "fname_label = data_path + '/MEG/sample/labels/%s' % label_name\n",
    "label = mne.read_label(fname_label)\n",
    "\n",
    "stcs = compute_source_psd_epochs(epochs_resampled['20'], inverse_operator, lambda2=lambda2,\n",
    "                                 method=method, fmin=0, fmax=40, label=label,\n",
    "                                 return_generator=True, verbose=True)\n",
    "\n",
    "\n",
    "# Averaging the epochs transform into an evoked array which is not the expected data but we have to average\n",
    "# Here we add directly and average them based on the number of events\n",
    "psd_avg = 0.\n",
    "for i, stc_loop in enumerate(stcs):\n",
    "    psd_avg += stc_loop.data\n",
    "psd_avg /= 5\n",
    "stc_loop.data = psd_avg \n",
    "\n",
    "brain = stc_loop.plot(\n",
    "        subject=subject, subjects_dir=subjects_dir, hemi='rh',\n",
    "        colormap='inferno', clim=dict(kind='percent', lims=(70, 85, 99)), smoothing_steps=10)\n",
    "\n",
    "brain.show_view(dict(azimuth=0, elevation=0), roll=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], dtype=int64),\n",
       " array([ 4602,  5356,  5357,  5358,  5374,  5393,  5403,  6177,  6178,\n",
       "         6194,  6195,  6212,  6213,  6214,  6230,  6231,  6232,  6233,\n",
       "         6234,  6253,  6254,  6255,  6256,  6275,  6276,  6277,  6334,\n",
       "         6335,  6336,  6337,  6338,  6343,  6344,  6345,  6346,  6347,\n",
       "         6348,  6349,  6359,  6360,  6361,  6362,  6363,  6364,  6371,\n",
       "         6372,  7070,  7071,  7072,  7088,  7089,  7090,  7105,  7106,\n",
       "         7123,  7124,  7135,  7136,  7137,  7157,  7158,  7180,  7210,\n",
       "         7211,  7219,  7220,  7221,  7222,  7223,  7224,  7237,  7238,\n",
       "         7239,  7240,  7241,  7242,  7243,  7244,  7254,  7256,  7257,\n",
       "         7258,  7259,  7260,  7272,  7273,  7274,  7275,  7976,  7977,\n",
       "         7990,  7991,  7992,  8014,  8015,  8034,  8035,  8053,  8072,\n",
       "         8073,  8096,  8097,  8098,  8119,  8120,  8121,  8134,  8135,\n",
       "         8136,  8145,  8146,  8147,  8148,  8149,  8150,  8158,  8159,\n",
       "         8160,  8161,  8162,  8163,  8178,  8179,  8180,  8958,  8959,\n",
       "         8960,  8961,  8962,  8963,  8973,  8974,  8975,  8976,  8998,\n",
       "         8999,  9000,  9018,  9019,  9020,  9021,  9035,  9036,  9055,\n",
       "         9056,  9078,  9093,  9112,  9113,  9127,  9128,  9129,  9130,\n",
       "         9131,  9132,  9144,  9145,  9146,  9147,  9944,  9945,  9957,\n",
       "         9958,  9959,  9960,  9961,  9962,  9974,  9975,  9976,  9977,\n",
       "         9996,  9997,  9998,  9999, 10014, 10015, 10016, 10017, 10018,\n",
       "        10035, 10036, 10037, 10038, 10039, 10056, 10057, 10058, 10059,\n",
       "        10071, 10072, 10073, 10074, 10088, 10089, 10090, 10091, 10113,\n",
       "        10114, 10115, 10116, 10117, 10126, 10127, 10128, 10129, 10130,\n",
       "        10131, 10141, 10142])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stc_loop.vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcs = apply_inverse_epochs(epochs_resampled['20'], inverse_operator, lambda2, method,\n",
    "                            pick_ori=\"normal\", return_generator=True)\n",
    "\n",
    "label = mne.read_label(fname_label)\n",
    "\n",
    "src = inverse_operator['src']  # the source space used\n",
    "seed_ts = mne.extract_label_time_course(stcs, label, src, mode='mean_flip',\n",
    "                                        verbose='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Created the whitener using a noise covariance matrix with rank 11 (80 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Processing epoch : 1 / 5\n",
      "Processing epoch : 2 / 5\n",
      "Processing epoch : 3 / 5\n",
      "Processing epoch : 4 / 5\n",
      "Processing epoch : 5 / 5\n"
     ]
    }
   ],
   "source": [
    "stcs = apply_inverse_epochs(epochs_resampled['20'], inverse_operator, lambda2, method,\n",
    "                            pick_ori=\"normal\", return_generator=True)\n",
    "comb_ts = list(zip(seed_ts, stcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Label | unknown, 'Vis-rh', rh : 623 vertices>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcs = apply_inverse_epochs(epochs_resampled, inverse_operator, lambda2, method,\n",
    "                            pick_ori=\"normal\", return_generator=True)\n",
    "\n",
    "src = inverse_operator['src']  # the source space used\n",
    "seed_ts = mne.extract_label_time_course(stcs, label, src, mode='mean_flip',\n",
    "                                        verbose='error')\n",
    "\n",
    "stcs = apply_inverse_epochs(epochs_resampled, inverse_operator, lambda2, method,\n",
    "                            pick_ori=\"normal\", return_generator=True)\n",
    "comb_ts = list(zip(seed_ts, stcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 1)\n",
      "    Created the whitener using a noise covariance matrix with rank 11 (80 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 11\n",
      "Using 78 tapers with bandwidth 4.0 Hz on 5 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a1abb4ed4d407ebd93d9dac021895b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_psd = np.mean(stc_psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 210 vertices, subject : fsaverage, tmin : 0.0 (ms), tmax : 40000.0 (ms), tstep : 50.0 (ms), data shape : (210, 801), ~1.3 MB>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stc_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_band(band):\n",
    "    \"\"\"Plot activity within a frequency band on the subject's brain.\"\"\"\n",
    "    #title = \"%s %s\\n(%d-%d Hz)\" % ((titles, band,) + freq_bands[band])\n",
    "    topos[band].plot_topomap(\n",
    "        times=0., scalings=1., cbar_fmt='%0.1f', vmin=0, cmap='inferno',\n",
    "        )\n",
    "\n",
    "fig_theta, brain_theta = plot_band('alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [2.98135283e-11 8.73588607e-11 1.59108586e-09]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.0, 0.0, 432.1112365722656, array([-0.59938049,  0.        ,  0.        ])),\n",
       " 0.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain = stc_psd.plot(\n",
    "        subject=subject, subjects_dir=subjects_dir, views='cau', hemi='both',\n",
    "         colormap='inferno',\n",
    "        time_viewer=False, show_traces=False,\n",
    "        clim=dict(kind='percent', lims=(70, 85, 99)), smoothing_steps=10)\n",
    "brain.show_view(dict(azimuth=0, elevation=0), roll=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Reading inverse operator decomposition from /homes/v20subra/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-oct-6-meg-inv.fif...\n",
      "    Reading inverse operator info...\n",
      "    [done]\n",
      "    Reading inverse operator decomposition...\n",
      "    [done]\n",
      "    305 x 305 full covariance (kind = 1) found.\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Noise covariance matrix read.\n",
      "    22494 x 22494 diagonal covariance (kind = 2) found.\n",
      "    Source covariance matrix read.\n",
      "    22494 x 22494 diagonal covariance (kind = 6) found.\n",
      "    Orientation priors read.\n",
      "    22494 x 22494 diagonal covariance (kind = 5) found.\n",
      "    Depth priors read.\n",
      "    Did not find the desired covariance matrix (kind = 3)\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Source spaces transformed to the inverse solution coordinate frame\n",
      "Opening raw data file /homes/v20subra/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Setting baseline interval to [-0.19979521315838786, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 3)\n",
      "3 projection items activated\n"
     ]
    }
   ],
   "source": [
    "from mne.minimum_norm import read_inverse_operator, compute_source_psd_epochs\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "data_path = sample.data_path()\n",
    "fname_inv = data_path + '/MEG/sample/sample_audvis-meg-oct-6-meg-inv.fif'\n",
    "fname_raw = data_path + '/MEG/sample/sample_audvis_raw.fif'\n",
    "fname_event = data_path + '/MEG/sample/sample_audvis_raw-eve.fif'\n",
    "label_name = 'Vis-rh'\n",
    "fname_label = data_path + '/MEG/sample/labels/%s.label' % label_name\n",
    "subjects_dir = data_path + '/subjects'\n",
    "\n",
    "event_id, tmin, tmax = 1, -0.2, 0.5\n",
    "snr = 1.0  # use smaller SNR for raw data\n",
    "lambda2 = 1.0 / snr ** 2\n",
    "method = \"dSPM\"  # use dSPM method (could also be MNE or sLORETA)\n",
    "\n",
    "# Load data\n",
    "inverse_operator = read_inverse_operator(fname_inv)\n",
    "label = mne.read_label(fname_label)\n",
    "raw = mne.io.read_raw_fif(fname_raw)\n",
    "events = mne.read_events(fname_event)\n",
    "\n",
    "# Set up pick list\n",
    "include = []\n",
    "raw.info['bads'] += ['EEG 053']  # bads + 1 more\n",
    "\n",
    "# pick MEG channels\n",
    "picks = mne.pick_types(raw.info, meg=True, eeg=False, stim=False, eog=True,\n",
    "                       include=include, exclude='bads')\n",
    "# Read epochs\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, picks=picks,\n",
    "                    baseline=(None, 0), reject=dict(mag=4e-12, grad=4000e-13,\n",
    "                                                    eog=150e-6))\n",
    "\n",
    "# define frequencies of interest\n",
    "fmin, fmax = 0., 70.\n",
    "bandwidth = 4.  # bandwidth of the windows in Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering frequencies 0 ... 70 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "    Created the whitener using a noise covariance matrix with rank 302 (3 small eigenvalues omitted)\n",
      "    Computing noise-normalization factors (dSPM)...\n",
      "[done]\n",
      "Picked 305 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "Reducing data rank 21 -> 21\n",
      "Using 2 tapers with bandwidth 4.0 Hz on at most 10 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c145ef49ef6d4fbe9d8f26934d2eccee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs_use = 10\n",
    "stcs = compute_source_psd_epochs(epochs[:n_epochs_use], inverse_operator,\n",
    "                                 lambda2=lambda2,\n",
    "                                 method=method, fmin=fmin, fmax=fmax,\n",
    "                                 bandwidth=bandwidth, label=label,\n",
    "                                 return_generator=True, verbose=True)\n",
    "\n",
    "# compute average PSD over the first 10 epochs\n",
    "psd_avg = 0.\n",
    "for i, stc in enumerate(stcs):\n",
    "    psd_avg += stc.data\n",
    "psd_avg /= n_epochs_use\n",
    "freqs = stc.times  # the frequencies are stored here\n",
    "stc.data = psd_avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = stc.plot(initial_time=10., hemi='rh', views='lat',  # 10 HZ\n",
    "                 clim=dict(kind='value', lims=(20, 40, 60)),\n",
    "                 smoothing_steps=3, subjects_dir=subjects_dir)\n",
    "brain.add_label(label, borders=True, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([    0,     1,     2, ..., 10239, 10240, 10241]),\n",
       " array([    0,     1,     2, ..., 10239, 10240, 10241])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stc[0].vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Label | unknown, 'Aud-lh', lh : 1097 vertices>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
