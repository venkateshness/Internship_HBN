{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pathlib\n",
    "from mne.externals.pymatreader import read_mat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import axes3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/users/local/Venkatesh/HBN/')\n",
    "subjs = sorted(os.listdir())[1:-2]\n",
    "#cd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/v20subra\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "S4B2/GSN_HydroCel_129_hbn.sfp not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1b9f7907db6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreparation_resting_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'task1/NDARBF805EHN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1b9f7907db6f>\u001b[0m in \u001b[0;36mpreparation_resting_state\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mpath_to_montage_ses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/usr/slurm/venkatesh/HBN/%s/EEG/preprocessed/csv_format/RestingState_chanlocs.csv'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mchans_glob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_custom_montage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'S4B2/GSN_HydroCel_129_hbn.sfp'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# read_montage is deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;31m# channels to exclude because noisy (Nentwich paper)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mne/channels/montage.py\u001b[0m in \u001b[0;36mread_custom_montage\u001b[0;34m(fname, head_size, coord_frame)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSUPPORTED_FILE_EXT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hydrocel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0mmontage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_sfp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSUPPORTED_FILE_EXT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'matlab'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mne/channels/_standard_montage_utils.py\u001b[0m in \u001b[0;36m_read_sfp\u001b[0;34m(fname, head_size)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mfid_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'FidNz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FidT9'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FidT10'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mch_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_np_loadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;31m# deal with \"headshape\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'headshape'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mch_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mne/channels/_standard_montage_utils.py\u001b[0m in \u001b[0;36m_safe_np_loadtxt\u001b[0;34m(fname, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_safe_np_loadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mch_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_str_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m             \u001b[0mfid_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: S4B2/GSN_HydroCel_129_hbn.sfp not found."
     ]
    }
   ],
   "source": [
    "def csv_to_raw_mne(path_to_file,path_to_montage_ses,fs,path_to_events,filename,montage = 'GSN-HydroCel-129'):\n",
    "    ''' Load csv files of data, chan locations and events and return a raw mne instance'''\n",
    "    data = np.loadtxt(path_to_file,delimiter =',')\n",
    "    chans = pd.read_csv(path_to_montage_ses,sep = ',',header = None)\n",
    "    ch_list=['E1', 'E8', 'E14', 'E17', 'E21', 'E25', 'E32', 'E38', 'E43', 'E44', 'E48', 'E49', 'E56', 'E57', 'E63', 'E64', 'E69', 'E73', 'E74', 'E81', 'E82', 'E88', 'E89', 'E94', 'E95', 'E99', 'E100', 'E107', 'E113', 'E114', 'E119', 'E120', 'E121', 'E125', 'E126', 'E127', 'E128']\n",
    "    ch_names = list(chans.values[1:,0])\n",
    "#print(type(ch_names))\n",
    "    #ch_names_appended = list(np.append(ch_names,'stim_channel'))\n",
    "    #print(len(data[0]))\n",
    "    types = ['eeg']*(len(ch_names))\n",
    "    #types.append('stim')\n",
    "    #data2 = np.zeros([1,len(data[0])]) #len(raw.times)\n",
    "    #data_appended = np.append(data,data2,axis = 0)\n",
    "\n",
    "    #print(np.shape(data_appended))\n",
    "#print(len(types))\n",
    "\n",
    "#types\n",
    "    info = mne.create_info(ch_names,sfreq = fs,ch_types = types)\n",
    "#raw=mne.io.RawArray(data, info)\n",
    "\n",
    "#mne.find_events(raw,stim_channel='stim')\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "    \n",
    "    # set standard montage\n",
    "    if montage:\n",
    "        raw.set_montage(montage)\n",
    "\n",
    "    # events array shape must be (n_events,3)The first column specifies the sample number of each event,\n",
    "    # the second column is ignored, and the third column provides the event value.\n",
    "    # If events already exist in the Raw instance at the given sample numbers, the event values will be added together.\n",
    "\n",
    "    if path_to_events:\n",
    "        # parse events file\n",
    "        raw_events = pd.read_csv(path_to_events, sep = r'\\s*,\\s*', header = None, engine = 'python')\n",
    "        values = raw_events[0].to_list()\n",
    "        \n",
    "        # identify markers start and stop recording\n",
    "        idx = [i for i, e in enumerate(values) if e == 'break cnt']\n",
    "        \n",
    "         \n",
    "        if filename == 'NDARDX770PJK':\n",
    "           \n",
    "            values.extend([\"break cnt\"])\n",
    "            \n",
    "            idx = [i for i, e in enumerate(values) if e == 'break cnt']\n",
    "        \n",
    "        samples = raw_events[1][1:idx[0]].to_numpy(dtype = int)\n",
    "        # slicing until '-1' means that we will not know about the last state. Hence removed.\n",
    "        event_values = raw_events[0][1:idx[0]].to_numpy(dtype = int)\n",
    "\n",
    "        \n",
    "        # append a last value for end of paradigm\n",
    "        ## I think 1 acts as an explicit EOF, but having this slicing until '-1' as indicated\n",
    "        # in the previous comment would not let us know the last state\n",
    "        # event_values = np.append(event_values, 1)\n",
    "\n",
    "        # Creating an array of len(samples)-1 would not have the sufficient length to add the \n",
    "        # sample's last row.\n",
    "        events = np.zeros((len(samples), 3))\n",
    "        \n",
    "        events = events.astype('int')\n",
    "        events[:, 0] = samples\n",
    "        events[:, 2] = event_values\n",
    "        \n",
    "        # Appending one row of 'ones'. Will be easier to stop parsing once we hit 1\n",
    "        events_final = np.append(events,np.ones((1, 3)),axis = 0).astype('int')\n",
    "        raw = exclude_channels_from_raw(raw, ch_list)\n",
    "        \n",
    "    return raw,events_final\n",
    "\n",
    "def exclude_channels_from_raw(raw,ch_to_exclude):\n",
    "    '''Return a raw structure where ch_to_exclude are removed'''\n",
    "    idx_keep = mne.pick_channels(raw.ch_names,include = raw.ch_names,exclude = ch_to_exclude)\n",
    "    raw.pick_channels([raw.ch_names[pick] for pick in idx_keep])\n",
    "    return raw\n",
    "\n",
    "\n",
    "\n",
    "def preparation_resting_state(filename):\n",
    "    path_to_file = '/usr/slurm/venkatesh/HBN/%s/EEG/preprocessed/csv_format/RestingState_data.csv'% filename\n",
    "    path_to_events = '/usr/slurm/venkatesh/HBN/%s/EEG/preprocessed/csv_format/RestingState_event.csv' %filename\n",
    "    path_to_montage_glob = '/S4B2/GSN_HydroCel_129_hbn.sfp'\n",
    "    path_to_montage_ses = '/usr/slurm/venkatesh/HBN/%s/EEG/preprocessed/csv_format/RestingState_chanlocs.csv' %filename\n",
    "    fs = 500\n",
    "    chans_glob = mne.channels.read_custom_montage(fname = 'S4B2/GSN_HydroCel_129_hbn.sfp') # read_montage is deprecated\n",
    "# channels to exclude because noisy (Nentwich paper)\n",
    "\n",
    "\n",
    "    raw, events = csv_to_raw_mne(path_to_file,path_to_montage_ses,fs,path_to_events,filename,montage = 'GSN-HydroCel-129')\n",
    "    #raw.add_events(events, stim_channel = 'stim_channel',replace = False)\n",
    "    return raw,events\n",
    "\n",
    "def preparation(filename):\n",
    "    path_to_file = '/usr/slurm/venkatesh/HBN/%s/EEG/preprocessed/csv_format/Video3_data.csv'% filename\n",
    "    path_to_events = '/usr/slurm/venkatesh/HBN/%s/EEG/preprocessed/csv_format/Video3_event.csv' %filename\n",
    "    path_to_montage_glob = '/S4B2/GSN_HydroCel_129_hbn.sfp'\n",
    "    path_to_montage_ses = '/usr/slurm/venkatesh/HBN/%s/EEG/preprocessed/csv_format/Video3_chanlocs.csv' %filename\n",
    "    fs = 500\n",
    "    chans_glob = mne.channels.read_custom_montage(fname = 'S4B2/GSN_HydroCel_129_hbn.sfp') # read_montage is deprecated\n",
    "# channels to exclude because noisy (Nentwich paper)\n",
    "\n",
    "\n",
    "    raw, events = csv_to_raw_mne(path_to_file,path_to_montage_ses,fs,path_to_events,filename,montage = 'GSN-HydroCel-129')\n",
    "    #raw.add_events(events, stim_channel = 'stim_channel',replace = False)\n",
    "    return raw,events\n",
    "\n",
    "\n",
    "a,b=preparation_resting_state('task1/NDARBF805EHN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=111, n_times=86040\n",
      "    Range : 0 ... 86039 =      0.000 ...   172.078 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=111, n_times=87720\n",
      "    Range : 0 ... 87719 =      0.000 ...   175.438 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=111, n_times=86030\n",
      "    Range : 0 ... 86029 =      0.000 ...   172.058 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=111, n_times=86092\n",
      "    Range : 0 ... 86091 =      0.000 ...   172.182 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=111, n_times=86564\n",
      "    Range : 0 ... 86563 =      0.000 ...   173.126 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=111, n_times=86045\n",
      "    Range : 0 ... 86044 =      0.000 ...   172.088 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=111, n_times=86058\n",
      "    Range : 0 ... 86057 =      0.000 ...   172.114 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=111, n_times=86046\n",
      "    Range : 0 ... 86045 =      0.000 ...   172.090 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=111, n_times=101177\n",
      "    Range : 0 ... 101176 =      0.000 ...   202.352 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=111, n_times=86054\n",
      "    Range : 0 ... 86053 =      0.000 ...   172.106 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "sub1_raw,sub1_events = preparation(subjs[0])\n",
    "sub2_raw,sub2_events = preparation(subjs[1])\n",
    "sub3_raw,sub3_events = preparation(subjs[2])\n",
    "sub4_raw,sub4_events = preparation(subjs[3])\n",
    "sub5_raw,sub5_events = preparation(subjs[4])\n",
    "sub6_raw,sub6_events = preparation(subjs[5])\n",
    "sub7_raw,sub7_events = preparation(subjs[6])\n",
    "sub8_raw,sub8_events = preparation(subjs[7])\n",
    "sub9_raw,sub9_events = preparation(subjs[8])\n",
    "sub10_raw,sub10_events = preparation(subjs[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs(subject_raw,subject_events):\n",
    "\n",
    "    epochs = mne.Epochs(subject_raw, subject_events, [83,103,9999], tmin=0, tmax=170,preload=True,baseline=(0,None))\n",
    "    epochs_resampled = epochs#.resample(250) # Downsampling to 250Hz\n",
    "    \n",
    "    return epochs_resampled['83']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "from timeit import default_timer\n",
    "\n",
    "\n",
    "def train_cca(data):\n",
    "    \"\"\"Run Correlated Component Analysis on your training data.\n",
    "        Parameters:\n",
    "        ----------\n",
    "        data : dict\n",
    "            Dictionary with keys are names of conditions and values are numpy\n",
    "            arrays structured like (subjects, channels, samples).\n",
    "            The number of channels must be the same between all conditions!\n",
    "        Returns:\n",
    "        -------\n",
    "        W : np.array\n",
    "            Columns are spatial filters. They are sorted in descending order, it means that first column-vector maximize\n",
    "            correlation the most.\n",
    "        ISC : np.array\n",
    "            Inter-subject correlation sorted in descending order\n",
    "    \"\"\"\n",
    "\n",
    "    start = default_timer()\n",
    "\n",
    "    C = len(data.keys())\n",
    "    print(f'train_cca - calculations started. There are {C} conditions')\n",
    "\n",
    "    gamma = 0.1\n",
    "    Rw, Rb = 0, 0\n",
    "    for cond in data.values():\n",
    "        N, D, T, = cond.shape\n",
    "        print(f'Condition has {N} subjects, {D} sensors and {T} samples')\n",
    "        cond = cond.reshape(D * N, T)\n",
    "\n",
    "        # Rij\n",
    "        Rij = np.swapaxes(np.reshape(np.cov(cond), (N, D, N, D)), 1, 2)\n",
    "        \n",
    "        # Rw\n",
    "        Rw = Rw + np.mean([Rij[i, i, :, :]\n",
    "                           for i in range(0, N)], axis=0)\n",
    "        \n",
    "        # Rb\n",
    "        Rb = Rb + np.mean([Rij[i, j, :, :]\n",
    "                           for i in range(0, N)\n",
    "                           for j in range(0, N) if i != j], axis=0)\n",
    "        covariance = np.cov(cond)\n",
    "    # Divide by number of condition\n",
    "    Rw, Rb = Rw/C, Rb/C\n",
    "\n",
    "    # Regularization\n",
    "    Rw_reg = (1 - gamma) * Rw + gamma * np.mean(eigh(Rw)[0]) * np.identity(Rw.shape[0])\n",
    "\n",
    "    # ISCs and Ws\n",
    "    [ISC, W] = eigh(Rb, Rw_reg) #Eigen values, W matrix\n",
    "    \n",
    "    # Make descending order\n",
    "    ISC, W = ISC[::-1], W[:, ::-1] \n",
    "    #print(ISC[0])\n",
    "    stop = default_timer()\n",
    "\n",
    "    print(f'Elapsed time: {round(stop - start)} seconds.')\n",
    "    return W, ISC\n",
    "\n",
    "\n",
    "def apply_cca(X, W, fs):\n",
    "    \"\"\"Applying precomputed spatial filters to your data.\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : ndarray\n",
    "            3-D numpy array structured like (subject, channel, sample)\n",
    "        W : ndarray\n",
    "            Spatial filters.\n",
    "        fs : int\n",
    "            Frequency sampling.\n",
    "        Returns:\n",
    "        -------\n",
    "        ISC : ndarray\n",
    "            Inter-subject correlations values are sorted in descending order.\n",
    "        ISC_persecond : ndarray\n",
    "            Inter-subject correlations values per second where first row is the most correlated.\n",
    "        ISC_bysubject : ndarray\n",
    "            Description goes here.\n",
    "        A : ndarray\n",
    "            Scalp projections of ISC.\n",
    "    \"\"\"\n",
    "\n",
    "    start = default_timer()\n",
    "    print('apply_cca - calculations started')\n",
    "\n",
    "    N, D, T = X.shape\n",
    "    # gamma = 0.1\n",
    "    window_sec = 5\n",
    "    X = X.reshape(D * N, T)\n",
    "    \n",
    "    # Rij\n",
    "    Rij = np.swapaxes(np.reshape(np.cov(X), (N, D, N, D)), 1, 2)\n",
    "\n",
    "    # Rw\n",
    "    Rw = np.mean([Rij[i, i, :, :]\n",
    "                  for i in range(0, N)], axis=0)\n",
    "    # Rw_reg = (1 - gamma) * Rw + gamma * np.mean(eigh(Rw)[0]) * np.identity(Rw.shape[0])\n",
    "\n",
    "    # Rb\n",
    "    Rb = np.mean([Rij[i, j, :, :]\n",
    "                  for i in range(0, N)\n",
    "                  for j in range(0, N) if i != j], axis=0)\n",
    "\n",
    "    # ISCs\n",
    "    ISC = np.sort(np.diag(np.transpose(W) @ Rb @ W) / np.diag(np.transpose(W) @ Rw @ W))[::-1]\n",
    "\n",
    "    # Scalp projections\n",
    "    A = np.linalg.solve(Rw @ W, np.transpose(W) @ Rw @ W)  # a, b. \n",
    "    \n",
    "    # ISC by subject\n",
    "    print('by subject is calculating')\n",
    "    ISC_bysubject = np.empty((D, N))\n",
    "\n",
    "    for subj_k in range(0, N):\n",
    "        Rw, Rb = 0, 0\n",
    "        Rw = np.mean([Rw + 1 / (N - 1) * (Rij[subj_k, subj_k, :, :] + Rij[subj_l, subj_l, :, :])\n",
    "                      for subj_l in range(0, N) if subj_k != subj_l], axis=0)\n",
    "        Rb = np.mean([Rb + 1 / (N - 1) * (Rij[subj_k, subj_l, :, :] + Rij[subj_l, subj_k, :, :])\n",
    "                      for subj_l in range(0, N) if subj_k != subj_l], axis=0)\n",
    "\n",
    "        ISC_bysubject[:, subj_k] = np.diag(np.transpose(W) @ Rb @ W) / np.diag(np.transpose(W) @ Rw @ W)\n",
    "\n",
    "    # ISC per second\n",
    "    print('by persecond is calculating')\n",
    "    ISC_persecond = np.empty((D, int(T / fs) ))\n",
    "    window_i = 0\n",
    "\n",
    "    for t in range(0, T, fs):\n",
    "\n",
    "        Xt = X[:, t:t+window_sec*fs] #[subj 1, subj 2........subj 10]\n",
    "       \n",
    "        # the covariance\n",
    "        Rij = np.cov(Xt) #910, 910for all the subjects \n",
    "        # <----10 subjects---->\n",
    "        #  [sub1, sub2... sub10 ] sub 1\n",
    "        #  [sub1, sub2... sub10 ] sub 2\n",
    "        #  [sub1, sub2... sub10 ] ..\n",
    "        #  [sub1, sub2... sub10 ] ..\n",
    "        #   [sub1, sub2... sub10 ] sub 10\n",
    "        \n",
    "        \n",
    "        \n",
    "        Rw = np.mean([Rij[i:i + D, i:i + D] # Correlation diagonally (itself)\n",
    "                      for i in range(0, D * N, D)], axis=0) \n",
    "        \n",
    "        Rb = np.mean([Rij[i:i + D, j:j + D]\n",
    "                      for i in range(0, D * N, D)\n",
    "                      for j in range(0, D * N, D) if i != j], axis=0) #Correlation with other subjects\n",
    "        \n",
    "        ISC_persecond[:, window_i] = np.diag(np.transpose(W) @ Rb @ W) / np.diag(np.transpose(W) @ Rw @ W)\n",
    "        window_i += 1\n",
    "        \n",
    "    stop = default_timer()\n",
    "    print(f'Elapsed time: {round(stop - start)} seconds.')\n",
    "\n",
    "    return ISC, ISC_persecond, ISC_bysubject, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dict()\n",
    "\n",
    "dic['condition1'] = np.append(sub1_raw.get_data()[:91,516:85516].reshape(1,91,85000),sub2_raw.get_data()[:91,516:85516].reshape(1,91,85000) ,axis=0)\n",
    "\n",
    "#for i in range(2,10):\n",
    "#    dic['condition1'] = np.append(dic['condition1'],sub[i].get_data()[:,:86030].reshape(1,92,86030) ,axis=0)\n",
    "\n",
    "dic['condition1'] = np.append(dic['condition1'],sub3_raw.get_data()[:91,516:85516].reshape(1,91,85000) ,axis=0)\n",
    "dic['condition1'] = np.append(dic['condition1'],sub4_raw.get_data()[:91,516:85516].reshape(1,91,85000) ,axis=0)\n",
    "dic['condition1'] = np.append(dic['condition1'],sub5_raw.get_data()[:91,516:85516].reshape(1,91,85000) ,axis=0)\n",
    "dic['condition1'] = np.append(dic['condition1'],sub6_raw.get_data()[:91,516:85516].reshape(1,91,85000) ,axis=0)\n",
    "dic['condition1'] = np.append(dic['condition1'],sub7_raw.get_data()[:91,516:85516].reshape(1,91,85000) ,axis=0)\n",
    "dic['condition1'] = np.append(dic['condition1'],sub8_raw.get_data()[:91,516:85516].reshape(1,91,85000) ,axis=0)\n",
    "dic['condition1'] = np.append(dic['condition1'],sub9_raw.get_data()[:91,516:85516].reshape(1,91,85000) ,axis=0)\n",
    "dic['condition1'] = np.append(dic['condition1'],sub10_raw.get_data()[:91,516:85516].reshape(1,91,85000) ,axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_cca - calculations started. There are 1 conditions\n",
      "Condition has 10 subjects, 91 sensors and 85000 samples\n",
      "Elapsed time: 3 seconds.\n",
      "apply_cca - calculations started\n",
      "by subject is calculating\n",
      "by persecond is calculating\n",
      "Elapsed time: 8 seconds.\n"
     ]
    }
   ],
   "source": [
    "[W,ISC] = train_cca(dic)\n",
    "#np.shape( sub1_raw.get_data() )\n",
    "\n",
    "isc_results = dict()\n",
    "for cond_key, cond_values in dic.items():\n",
    "    isc_results[str(cond_key)] = dict(zip(['ISC', 'ISC_persecond', 'ISC_bysubject', 'A'], apply_cca(cond_values, W, 500)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[29,33],[67,71],[77,83],[130,135],[155,164]]]\n",
    "\n",
    "#np.max(valstest,axis=0)\n",
    "\n",
    "#significance\n",
    "indexes = np.hstack([np.arange(159*500-1000,159*500+1060)])#,np.arange(67*500,72*500),np.arange(77*500,84*500),np.arange(130*500,136*500),np.arange(155*500,165*500)])\n",
    "indexes2 = np.hstack([np.arange(100*500-1000,100*500+1060)])\n",
    "#np.where(isc_results['condition1']['ISC_persecond'][0] == isc_results['condition1']['ISC_persecond'][0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isc_results['condition1']['A'][0]\n",
    "#sub1_trial = isc_results['condition1']['A'][0] @ sub1_raw.get_data()\n",
    "import tqdm\n",
    "#sub1_trial = np.zeros([91,85001])\n",
    "#a = [sub1_trial[:,i] (sub1_raw.get_data()[:,i]*isc_results['condition1']['A'][0]) for i in tqdm.tqdm(range(86040))]\n",
    " #sub1_trial[:,i] = (sub1_raw.get_data()[:,i]*isc_results['condition1']['A'][0])   \n",
    "\n",
    "def element_wise_multi(epochs):\n",
    "    subjects = isc_results['condition1']['A'][0].T @ epochs\n",
    "    return subjects\n",
    "\n",
    "def spatial_filter(epochs):\n",
    "    subjects = np.multiply(epochs.T,isc_results['condition1']['A'][0])\n",
    "    print(np.shape(subjects))\n",
    "    subjects_final = np.reshape(subjects,[1,91,2060])\n",
    "    return subjects_final\n",
    "#np.shape(element_wise_multi(epochs1_ISC_ts.get_data()[:,:,indexes]))\n",
    "\n",
    "#np.shape(isc_results['condition1']['A'][0],sub1_raw.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "Setting baseline interval to [0.0, 170.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 3 events and 85001 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "Setting baseline interval to [0.0, 170.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 3 events and 85001 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "Setting baseline interval to [0.0, 170.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 3 events and 85001 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "Setting baseline interval to [0.0, 170.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 3 events and 85001 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "Setting baseline interval to [0.0, 170.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 3 events and 85001 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "Setting baseline interval to [0.0, 170.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 3 events and 85001 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "Setting baseline interval to [0.0, 170.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 3 events and 85001 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "Setting baseline interval to [0.0, 170.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 3 events and 85001 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "Setting baseline interval to [0.0, 170.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 3 events and 85001 original time points ...\n",
      "1 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "Setting baseline interval to [0.0, 170.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 3 events and 85001 original time points ...\n",
      "1 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "epochs1_ISC_ts = epochs(sub1_raw,sub1_events)\n",
    "epochs2_ISC_ts = epochs(sub2_raw,sub2_events)\n",
    "epochs3_ISC_ts = epochs(sub3_raw,sub3_events)\n",
    "epochs4_ISC_ts = epochs(sub4_raw,sub4_events)\n",
    "epochs5_ISC_ts = epochs(sub5_raw,sub5_events)\n",
    "epochs6_ISC_ts = epochs(sub6_raw,sub6_events)\n",
    "epochs7_ISC_ts = epochs(sub7_raw,sub7_events)\n",
    "epochs8_ISC_ts = epochs(sub8_raw,sub8_events)\n",
    "epochs9_ISC_ts = epochs(sub9_raw,sub9_events)\n",
    "epochs10_ISC_ts = epochs(sub10_raw,sub10_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_epochs_data(epochs):\n",
    "\n",
    "    info = mne.create_info(sub1_raw.info['ch_names'],sfreq=500,ch_types = 'eeg')\n",
    "\n",
    "    raw = mne.io.RawArray(epochs.reshape(91,2060),info)\n",
    "    ep = mne.EpochsArray(epochs.reshape(1,91,2060),info)\n",
    "    raw.set_montage('GSN-HydroCel-129')\n",
    "    return info, raw, ep\n",
    "\n",
    "def get_raw_epochs_data_elem(epochs):\n",
    "\n",
    "    info = mne.create_info(['E1'],sfreq=500,ch_types = 'eeg')\n",
    "\n",
    "    raw = mne.io.RawArray(epochs.reshape(1,2060),info)\n",
    "    ep = mne.EpochsArray(epochs.reshape(1,1,2060),info)\n",
    "    raw.set_montage('GSN-HydroCel-129')\n",
    "    return info, raw, ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files missing from root.txt in /homes/v20subra/mne_data/MNE-fsaverage-data\n",
      "0 files missing from bem.txt in /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage\n"
     ]
    }
   ],
   "source": [
    "from mne.datasets import fetch_fsaverage\n",
    "\n",
    "import os.path as op\n",
    "fs_dir = fetch_fsaverage(verbose=True)\n",
    "subjects_dir = op.dirname(fs_dir)\n",
    "\n",
    "\n",
    "subject = 'fsaverage' # Subject ID for the MRI-head transformation\n",
    "trans = 'fsaverage'  # MNE has a built-in fsaverage transformation\n",
    "source_space = op.join(fs_dir, 'bem', 'fsaverage-ico-5-src.fif') \n",
    "\n",
    "bem = op.join(fs_dir, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source space          : /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif\n",
      "MRI -> head transform : /homes/v20subra/.local/lib/python3.8/site-packages/mne/data/fsaverage/fsaverage-trans.fif\n",
      "Measurement data      : instance of Info\n",
      "Conductor model   : /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n",
      "Accurate field computations\n",
      "Do computations in head coordinates\n",
      "Free source orientations\n",
      "\n",
      "Reading /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-ico-5-src.fif...\n",
      "Read 2 source spaces a total of 20484 active source locations\n",
      "\n",
      "Coordinate transformation: MRI (surface RAS) -> head\n",
      "     0.999994  0.003552  0.000202      -1.76 mm\n",
      "    -0.003558  0.998389  0.056626      31.09 mm\n",
      "    -0.000001 -0.056626  0.998395      39.60 mm\n",
      "     0.000000  0.000000  0.000000       1.00\n",
      "\n",
      "Read  91 EEG channels from info\n",
      "Head coordinate coil definitions created.\n",
      "Source spaces are now in head coordinates.\n",
      "\n",
      "Setting up the BEM model using /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif...\n",
      "\n",
      "Loading surfaces...\n",
      "\n",
      "Loading the solution matrix...\n",
      "\n",
      "Three-layer model surfaces loaded.\n",
      "Loaded linear_collocation BEM solution from /homes/v20subra/mne_data/MNE-fsaverage-data/fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif\n",
      "Employing the head->MRI coordinate transform with the BEM model.\n",
      "BEM model fsaverage-5120-5120-5120-bem-sol.fif is now set up\n",
      "\n",
      "Source spaces are in head coordinates.\n",
      "Checking that the sources are inside the surface and at least    5.0 mm away (will take a few...)\n",
      "    Skipping interior check for 2433 sources that fit inside a sphere of radius   47.7 mm\n",
      "    Skipping solid angle check for 0 points using Qhull\n",
      "    Skipping interior check for 2241 sources that fit inside a sphere of radius   47.7 mm\n",
      "    Skipping solid angle check for 0 points using Qhull\n",
      "\n",
      "Setting up for EEG...\n",
      "Computing EEG at 20484 source locations (free orientations)...\n",
      "\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "from mne.minimum_norm import make_inverse_operator, apply_inverse, apply_inverse_epochs\n",
    "\n",
    "fwd_model = mne.make_forward_solution(sub1_raw.info, trans=trans, src=source_space, bem=bem, eeg=True, mindist=5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"eLORETA\"\n",
    "snr = 3.\n",
    "lambda2 = 1. / snr ** 2\n",
    "\n",
    "# epochs['30'].average() = Averaged evoked response for the event 30\n",
    "#stc = apply_inverse_epochs(epochs_resampled, inverse_operator, lambda2,\n",
    " #                            method=method, pick_ori=None, verbose=True)\n",
    "#    return stc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_source_psd(raw):\n",
    " \n",
    "    noise_cov = mne.compute_raw_covariance(raw)\n",
    "    inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
    "        raw.info, forward=fwd_model, noise_cov=noise_cov, verbose=True)\n",
    "\n",
    "    stc_psd, sensor_psd = mne.minimum_norm.compute_source_psd(\n",
    "        raw, inverse_operator, lambda2=lambda2,method=method,fmax=40,\n",
    "        dB=False, return_sensor=True, verbose=True)\n",
    "    \n",
    "\n",
    "\n",
    "    freq_bands = dict(\n",
    "        delta=(2, 4), theta=(5, 7), alpha=(8, 13), beta=(15, 29), gamma=(30, 40))\n",
    "    topos = dict(vv=dict(), opm=dict())\n",
    "    stcs_dict = dict(vv=dict(), opm=dict())\n",
    "    \n",
    "    \n",
    "    topo_norm = sensor_psd.data.sum(axis=1, keepdims=True)\n",
    "    stc_norm = stc_psd.sum() \n",
    "\n",
    "    for band, limits in freq_bands.items():\n",
    "        data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n",
    "        topos[band] = mne.EvokedArray(\n",
    "            100 * data / topo_norm, sensor_psd.info)\n",
    "        stcs_dict[band] = \\\n",
    "            100 * stc_psd.copy().crop(*limits).sum() / stc_norm.data\n",
    "    \n",
    "    return stcs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs1_ISC_ts_filtered_high = spatial_filter(np.reshape( epochs1_ISC_ts.get_data()[:,:,indexes], [91,2060]))\n",
    "epochs2_ISC_ts_filtered_high = spatial_filter(np.reshape( epochs2_ISC_ts.get_data()[:,:,indexes], [91,2060]))\n",
    "epochs3_ISC_ts_filtered_high = spatial_filter(np.reshape( epochs3_ISC_ts.get_data()[:,:,indexes], [91,2060]))\n",
    "epochs4_ISC_ts_filtered_high = spatial_filter(np.reshape( epochs4_ISC_ts.get_data()[:,:,indexes], [91,2060]))\n",
    "epochs5_ISC_ts_filtered_high = spatial_filter(np.reshape( epochs5_ISC_ts.get_data()[:,:,indexes], [91,2060]))\n",
    "epochs6_ISC_ts_filtered_high = spatial_filter(np.reshape( epochs6_ISC_ts.get_data()[:,:,indexes], [91,2060]))\n",
    "epochs7_ISC_ts_filtered_high = spatial_filter(np.reshape( epochs7_ISC_ts.get_data()[:,:,indexes], [91,2060]))\n",
    "epochs8_ISC_ts_filtered_high = spatial_filter(np.reshape( epochs8_ISC_ts.get_data()[:,:,indexes], [91,2060]))\n",
    "epochs9_ISC_ts_filtered_high = spatial_filter(np.reshape( epochs9_ISC_ts.get_data()[:,:,indexes], [91,2060]))\n",
    "epochs10_ISC_ts_filtered_high = spatial_filter(np.reshape( epochs10_ISC_ts.get_data()[:,:,indexes], [91,2060]))\n",
    "#(epochs10_ISC_ts.get_data()[:,:,indexes])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "info1,raw1,ep1 = get_raw_epochs_data(epochs1_ISC_ts_filtered_high)\n",
    "info2,raw2,ep2 = get_raw_epochs_data(epochs2_ISC_ts_filtered_high)\n",
    "info3,raw3,ep3 = get_raw_epochs_data(epochs3_ISC_ts_filtered_high)\n",
    "info4,raw4,ep4 = get_raw_epochs_data(epochs4_ISC_ts_filtered_high)\n",
    "info5,raw5,ep5 = get_raw_epochs_data(epochs5_ISC_ts_filtered_high)\n",
    "info6,raw6,ep6 = get_raw_epochs_data(epochs6_ISC_ts_filtered_high)\n",
    "info7,raw7,ep7 = get_raw_epochs_data(epochs7_ISC_ts_filtered_high)\n",
    "info8,raw8,ep8 = get_raw_epochs_data(epochs8_ISC_ts_filtered_high)\n",
    "info9,raw9,ep9 = get_raw_epochs_data(epochs9_ISC_ts_filtered_high)\n",
    "info10,raw10,ep10 = get_raw_epochs_data(epochs10_ISC_ts_filtered_high)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n",
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4.1e-05 (2.2e-16 eps * 91 dim * 2e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 5.54879\n",
      "    scaling factor to adjust the trace = 1.8159e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 8 (7.3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52510fe9b8b4ca39f8be46f17ef083e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 0.00016 (2.2e-16 eps * 91 dim * 8e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 6.27275\n",
      "    scaling factor to adjust the trace = 6.11853e+10 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (6.7e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ea394b9e1c4f1d95a9df375ea58cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 6.4e-05 (2.2e-16 eps * 91 dim * 3.2e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 5.52394\n",
      "    scaling factor to adjust the trace = 2.14813e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3.7e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adba69b05cd490095c02d5402df1ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 8.5e-05 (2.2e-16 eps * 91 dim * 4.2e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 6.80831\n",
      "    scaling factor to adjust the trace = 1.50476e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 8 (9e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c384c1f2d8114ef69b143b774fd29603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 0.00046 (2.2e-16 eps * 91 dim * 2.3e+10  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 5.70094\n",
      "    scaling factor to adjust the trace = 2.72445e+10 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (6.8e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bd0a68aef04382b41453848bb4affa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 0.0003 (2.2e-16 eps * 91 dim * 1.5e+10  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 6.39358\n",
      "    scaling factor to adjust the trace = 9.59732e+10 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (5.3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aad2a8c75e44558a7af5ea2d9ee6de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 3.1e-05 (2.2e-16 eps * 91 dim * 1.5e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 5.46861\n",
      "    scaling factor to adjust the trace = 2.60022e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3.2e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4107521c4a5d4a67ae2ed340ffaafb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 7.3e-05 (2.2e-16 eps * 91 dim * 3.6e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 5.64278\n",
      "    scaling factor to adjust the trace = 1.5925e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (5.3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b47994dd8344d2a261cf7039b0f390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 3.2e-05 (2.2e-16 eps * 91 dim * 1.6e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 5.795\n",
      "    scaling factor to adjust the trace = 1.85121e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (5.3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0763321e74e64ebf89b0bfd239fc6743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 0.00018 (2.2e-16 eps * 91 dim * 8.7e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 6.26896\n",
      "    scaling factor to adjust the trace = 7.59786e+10 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3.7e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13388ecdc7b84345a3f6db9ea5b37174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for the top and bottom 10%ile calculation for the source estimation of non-spatially filtered EEG\n",
    "stc1_high = comp_source_psd(raw1)\n",
    "stc2_high = comp_source_psd(raw2)\n",
    "stc3_high = comp_source_psd(raw3)\n",
    "stc4_high = comp_source_psd(raw4)\n",
    "stc5_high = comp_source_psd(raw5)\n",
    "stc6_high = comp_source_psd(raw6)\n",
    "stc7_high = comp_source_psd(raw7)\n",
    "stc8_high = comp_source_psd(raw8)\n",
    "stc9_high = comp_source_psd(raw9)\n",
    "stc10_high = comp_source_psd(raw10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "(2060, 91)\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Creating RawArray with float64 data, n_channels=91, n_times=2060\n",
      "    Range : 0 ... 2059 =      0.000 ...     4.118 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "#Low\n",
    "epochs1_ISC_ts_filtered_low = spatial_filter(np.reshape( epochs1_ISC_ts.get_data()[:,:,indexes2], [91,2060]))\n",
    "epochs2_ISC_ts_filtered_low = spatial_filter(np.reshape( epochs2_ISC_ts.get_data()[:,:,indexes2], [91,2060]))\n",
    "epochs3_ISC_ts_filtered_low = spatial_filter(np.reshape( epochs3_ISC_ts.get_data()[:,:,indexes2], [91,2060]))\n",
    "epochs4_ISC_ts_filtered_low = spatial_filter(np.reshape( epochs4_ISC_ts.get_data()[:,:,indexes2], [91,2060]))\n",
    "epochs5_ISC_ts_filtered_low = spatial_filter(np.reshape( epochs5_ISC_ts.get_data()[:,:,indexes2], [91,2060]))\n",
    "epochs6_ISC_ts_filtered_low = spatial_filter(np.reshape( epochs6_ISC_ts.get_data()[:,:,indexes2], [91,2060]))\n",
    "epochs7_ISC_ts_filtered_low = spatial_filter(np.reshape( epochs7_ISC_ts.get_data()[:,:,indexes2], [91,2060]))\n",
    "epochs8_ISC_ts_filtered_low = spatial_filter(np.reshape( epochs8_ISC_ts.get_data()[:,:,indexes2], [91,2060]))\n",
    "epochs9_ISC_ts_filtered_low = spatial_filter(np.reshape( epochs9_ISC_ts.get_data()[:,:,indexes2], [91,2060]))\n",
    "epochs10_ISC_ts_filtered_low = spatial_filter(np.reshape( epochs10_ISC_ts.get_data()[:,:,indexes2], [91,2060]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "info1_low,raw1_low,ep1_low = get_raw_epochs_data(epochs1_ISC_ts_filtered_low)\n",
    "info2_low,raw2_low,ep2_low = get_raw_epochs_data(epochs2_ISC_ts_filtered_low)\n",
    "info3_low,raw3_low,ep3_low = get_raw_epochs_data(epochs3_ISC_ts_filtered_low)\n",
    "info4_low,raw4_low,ep4_low = get_raw_epochs_data(epochs4_ISC_ts_filtered_low)\n",
    "info5_low,raw5_low,ep5_low = get_raw_epochs_data(epochs5_ISC_ts_filtered_low)\n",
    "info6_low,raw6_low,ep6_low = get_raw_epochs_data(epochs6_ISC_ts_filtered_low)\n",
    "info7_low,raw7_low,ep7_low = get_raw_epochs_data(epochs7_ISC_ts_filtered_low)\n",
    "info8_low,raw8_low,ep8_low = get_raw_epochs_data(epochs8_ISC_ts_filtered_low)\n",
    "info9_low,raw9_low,ep9_low = get_raw_epochs_data(epochs9_ISC_ts_filtered_low)\n",
    "info10_low,raw10_low,ep10_low = get_raw_epochs_data(epochs10_ISC_ts_filtered_low)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n",
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4.3e-05 (2.2e-16 eps * 91 dim * 2.1e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 6.06953\n",
      "    scaling factor to adjust the trace = 2.08079e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3.3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bd42bba5ae435d93803e9f3966d410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 0.00012 (2.2e-16 eps * 91 dim * 6.2e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 6.0736\n",
      "    scaling factor to adjust the trace = 7.17508e+10 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (2.9e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfc66c16f3b42648a28a0b48fde61a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4.3e-05 (2.2e-16 eps * 91 dim * 2.2e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 5.72831\n",
      "    scaling factor to adjust the trace = 1.92601e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3.8e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d171096d5c74f11b1a399fd4101069b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 7.2e-05 (2.2e-16 eps * 91 dim * 3.6e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 6.05547\n",
      "    scaling factor to adjust the trace = 1.52748e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (2.7e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85d78ddb68241bebaf1f08585895263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 0.00025 (2.2e-16 eps * 91 dim * 1.3e+10  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 5.72404\n",
      "    scaling factor to adjust the trace = 3.536e+10 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3.3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba214f6a25a047e4b52913609cc5acaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 0.00049 (2.2e-16 eps * 91 dim * 2.4e+10  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 5.62317\n",
      "    scaling factor to adjust the trace = 4.34874e+10 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (6.8e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f109d0ca222949e08aae54e7b15cd63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.8e-05 (2.2e-16 eps * 91 dim * 1.4e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 6.02591\n",
      "    scaling factor to adjust the trace = 2.79296e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 8 (7.7e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d027af76d6734d04b53fe0eb162d1bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 5.5e-05 (2.2e-16 eps * 91 dim * 2.7e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 6.07496\n",
      "    scaling factor to adjust the trace = 1.29124e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3.4e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f269c01972594b2ebf7e84718fef53f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4.5e-05 (2.2e-16 eps * 91 dim * 2.2e+09  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 5.50177\n",
      "    scaling factor to adjust the trace = 1.53286e+11 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 8 (8.7e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6a2b321dc649b0a5d63111ef547a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using up to 20 segments\n",
      "Number of samples used : 2000\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    No patch info available. The standard source space normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 91 channels.\n",
      "    91 out of 91 channels remain after picking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 91 channels\n",
      "Creating the depth weighting matrix...\n",
      "    91 EEG channels\n",
      "    limit = 20485/20484 = 2.194331\n",
      "    scale = 146509 exp = 0.8\n",
      "Applying loose dipole orientations to surface source spaces: 0.2\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 0.00042 (2.2e-16 eps * 91 dim * 2.1e+10  max singular value)\n",
      "    Estimated rank (eeg): 91\n",
      "    EEG: rank 91 computed from 91 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
      "<ipython-input-17-555f416cc34f>:4: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  inverse_operator = mne.minimum_norm.make_inverse_operator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    largest singular value = 6.04451\n",
      "    scaling factor to adjust the trace = 5.94789e+10 (nchan = 91 nzero = 0)\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "2 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Considering frequencies 0 ... 40 Hz\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 91 (0 small eigenvalues omitted)\n",
      "    Computing optimized source covariance (eLORETA)...\n",
      "        Using independent orientation weights\n",
      "        Fitting up to 20 iterations (this make take a while)...\n",
      "        Converged on iteration 9 (3e-07 < 1e-06)\n",
      "        Updating inverse with weighted eigen leads\n",
      "[done]\n",
      "Picked 91 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads already weighted ... \n",
      "Reducing data rank 91 -> 91\n",
      "Using hann windowing on at most 2 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a28f0049a5440aa0df019db0ecae58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          |  : 0/2 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-555f416cc34f>:23: RuntimeWarning: tmax is not in Evoked time interval. tmax is set to evoked.tmax (39.7949 sec)\n",
      "  data = sensor_psd.copy().crop(*limits).data.sum(axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "stc1_low = comp_source_psd(raw1_low)\n",
    "stc2_low = comp_source_psd(raw2_low)\n",
    "stc3_low = comp_source_psd(raw3_low)\n",
    "stc4_low = comp_source_psd(raw4_low)\n",
    "stc5_low = comp_source_psd(raw5_low)\n",
    "stc6_low = comp_source_psd(raw6_low)\n",
    "stc7_low = comp_source_psd(raw7_low)\n",
    "stc8_low = comp_source_psd(raw8_low)\n",
    "stc9_low = comp_source_psd(raw9_low)\n",
    "stc10_low = comp_source_psd(raw10_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_minus_low(high,low,band):\n",
    "    return high[band] - low[band]\n",
    "\n",
    "def difference_and_t_test(band):\n",
    "    alpha_difference_1 = high_minus_low(stc1_high,stc1_low,band)\n",
    "    alpha_difference_2 = high_minus_low(stc2_high,stc2_low,band)\n",
    "    alpha_difference_3 = high_minus_low(stc3_high,stc3_low,band)\n",
    "    alpha_difference_4 = high_minus_low(stc4_high,stc4_low,band)\n",
    "    alpha_difference_5 = high_minus_low(stc5_high,stc5_low,band)\n",
    "    alpha_difference_6 = high_minus_low(stc6_high,stc6_low,band)\n",
    "    alpha_difference_7 = high_minus_low(stc7_high,stc7_low,band)\n",
    "    alpha_difference_8 = high_minus_low(stc8_high,stc8_low,band)\n",
    "    alpha_difference_9 = high_minus_low(stc9_high,stc9_low,band)\n",
    "    alpha_difference_10 = high_minus_low(stc10_high,stc10_low,band)\n",
    "    averaged_alpha =(alpha_difference_1+alpha_difference_2+alpha_difference_3+alpha_difference_4+alpha_difference_5\\\n",
    "          +alpha_difference_6+alpha_difference_7+alpha_difference_8+alpha_difference_9+alpha_difference_10)/10\n",
    "    a,b,c = mne.stats.permutation_t_test(averaged_alpha.data,n_permutations=1000)\n",
    "    alpha_stacked = (np.hstack((alpha_difference_1.data,alpha_difference_2.data,\\\n",
    "                   alpha_difference_3.data,alpha_difference_4.data,\\\n",
    "                   alpha_difference_5.data,alpha_difference_6.data,\\\n",
    "                   alpha_difference_7.data,alpha_difference_8.data,\\\n",
    "                   alpha_difference_9.data,alpha_difference_10.data)))\n",
    "    return averaged_alpha,alpha_stacked,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuting 999 times...\n"
     ]
    }
   ],
   "source": [
    "averaged,to_test,b = difference_and_t_test('delta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_for_slicing_beyond_percentiles = np.where( np.logical_or( (averaged.data <np.percentile(averaged.data,10)), (averaged.data>np.percentile(averaged.data,90))))\n",
    "\n",
    "averaged.data[list(set(list(range(20484)))-set(indices_for_slicing_beyond_percentiles[0]))] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 20484 vertices, subject : fsaverage, tmin : 3051.7578125 (ms), tmax : 3051.7578125 (ms), tstep : 2197.265625 (ms), data shape : (20484, 1), ~320 kB>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "fsaverage = datasets.fetch_surf_fsaverage()\n",
    "from nilearn import plotting\n",
    "\n",
    "view= plotting.view_surf(fsaverage.infl_right,averaged.data[10242:],cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nilearn(0,10242,'Alpha band')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainspace.mesh\n",
    "mesh = brainspace.mesh.mesh_io.read_surface('S4B2/brainnotation/tpl-fsaverage_den-10k_hemi-L_pial.surf.gii')\n",
    "mesh2 = brainspace.mesh.mesh_io.read_surface('S4B2/brainnotation/tpl-fsaverage_den-10k_hemi-R_pial.surf.gii')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surfplot import Plot\n",
    "%matplotlib qt\n",
    "%gui qt\n",
    "p = Plot(mesh,mesh2,zoom=1.2, views='lateral')\n",
    "p.add_layer(averaged.data, cmap='seismic')\n",
    "fig = p.build()\n",
    "plt.title('plt.title() has worked !!')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuting 999 times...\n"
     ]
    }
   ],
   "source": [
    "averaged,to_test,b = difference_and_t_test('theta')\n",
    "indices_for_slicing_beyond_percentiles = np.where( np.logical_or( (averaged.data <np.percentile(averaged.data,10)), (averaged.data>np.percentile(averaged.data,90))))\n",
    "\n",
    "averaged.data[list(set(list(range(20484)))-set(indices_for_slicing_beyond_percentiles[0]))] =0\n",
    "p = Plot(mesh,mesh2,zoom=1.2, views='lateral')\n",
    "p.add_layer(averaged.data, cmap='seismic')\n",
    "fig = p.build()\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def surf_plot(band):\n",
    "    averaged,to_test,b = difference_and_t_test(band)\n",
    "    indices_for_slicing_beyond_percentiles = np.where( np.logical_or( (averaged.data <np.percentile(averaged.data,10)), (averaged.data>np.percentile(averaged.data,90))))\n",
    "\n",
    "    averaged.data[list(set(list(range(20484)))-set(indices_for_slicing_beyond_percentiles[0]))] =0\n",
    "    p = Plot(mesh,mesh2,zoom=1.2, views='lateral')\n",
    "    p.add_layer(averaged.data, cmap='seismic')\n",
    "    fig = p.build()\n",
    "    plt.title('%s band'%band)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuting 999 times...\n",
      "Permuting 999 times...\n",
      "Permuting 999 times...\n",
      "Permuting 999 times...\n",
      "Permuting 999 times...\n"
     ]
    }
   ],
   "source": [
    "surf_plot('delta')\n",
    "surf_plot('theta')\n",
    "surf_plot('alpha')\n",
    "surf_plot('beta')\n",
    "surf_plot('gamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/v20subra\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permuting 999 times...\n",
      "<SourceEstimate | 20484 vertices, subject : fsaverage, tmin : 10620.1171875 (ms), tmax : 10620.1171875 (ms), tstep : 5126.953125 (ms), data shape : (20484, 1), ~320 kB>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'alpha band (source level)')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band = ['theta','alpha','beta','gamma','delta']\n",
    "\n",
    "l = difference_and_t_test(band[1])\n",
    "plt.xlabel('p-value = {}'.format(l[2]))\n",
    "print(l[0])\n",
    "plt.boxplot(l[0].data)\n",
    "plt.title('{} band (source level)'.format(band[1]))\n",
    "#plt.savefig('{} band(source level).jpg'.format(band[0]))\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "mat = scipy.io.loadmat('S4B2/subject_list.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'good_EEG', 'not_bad_EEG', 'ratingsAuto'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.DataFrame(mat['good_EEG'])\n",
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.random.randn(10,100,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition has 10 subjects, 100 sensors and 2 samples\n"
     ]
    }
   ],
   "source": [
    "#C = len(data.keys())\n",
    "#print(f'train_cca - calculations started. There are {C} conditions')\n",
    "\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "\n",
    "gamma = 0.1\n",
    "Rw, Rb = 0, 0\n",
    "#for cond in data.values():\n",
    "N, D, T, = a.shape\n",
    "print(f'Condition has {N} subjects, {D} sensors and {T} samples')\n",
    "cond = a.reshape(D * N, T)\n",
    "\n",
    "        # Rij\n",
    "Rij = np.swapaxes(np.reshape(np.cov(cond), (N, D, N, D)), 1, 2)\n",
    "        \n",
    "        # Rw\n",
    "Rw = Rw + np.mean([Rij[i, i, :, :]\n",
    "                           for i in range(0, N)], axis=0)\n",
    "        \n",
    "        # Rb\n",
    "Rb = Rb + np.mean([Rij[i, j, :, :]\n",
    "                           for i in range(0, N)\n",
    "                           for j in range(0, N) if i != j], axis=0)\n",
    "covariance = np.cov(cond)\n",
    "    # Divide by number of condition\n",
    "C=1\n",
    "Rw, Rb = Rw/C, Rb/C\n",
    "\n",
    "    # Regularization\n",
    "Rw_reg = (1 - gamma) * Rw + gamma * np.mean(eigh(Rw)[0]) * np.identity(Rw.shape[0])\n",
    "\n",
    "    # ISCs and Ws\n",
    "[ISC, W] = eigh(Rb, Rw_reg) #Eigen values, W matrix\n",
    "    \n",
    "    # Make descending order\n",
    "ISC, W = ISC[::-1], W[:, ::-1] \n",
    "    #print(ISC[0])\n",
    "#stop = default_timer()\n",
    "\n",
    "#print(f'Elapsed time: {round(stop - start)} seconds.')\n",
    "    #return W, ISC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02585155, -0.19231059,  0.31268809, ..., -0.00220239,\n",
       "        -0.03220372,  0.02940899],\n",
       "       [-0.01616133, -0.07371589, -0.00110485, ..., -0.04106293,\n",
       "         0.03372758, -0.02242619],\n",
       "       [ 0.00330279,  0.05193175,  0.40651712, ..., -0.03326729,\n",
       "        -0.05066275, -0.01251434],\n",
       "       ...,\n",
       "       [ 0.00793201,  0.13764298, -0.0111789 , ..., -0.03353268,\n",
       "        -0.01360116, -0.02109327],\n",
       "       [ 0.00183948,  0.30295573,  0.01314225, ...,  0.01677605,\n",
       "        -0.00705577,  0.01947321],\n",
       "       [ 0.07414329,  0.45278495, -0.53812491, ..., -0.02463864,\n",
       "        -0.03179194,  0.03524768]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92829162]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rij[1,1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
